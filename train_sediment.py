import itertools
from prophet import Prophet
from prophet.diagnostics import cross_validation, performance_metrics
import pandas as pd
import numpy as np
import time
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

start = time.time()

# ===============================
# C·∫§U H√åNH CH·ªà TI√äU D·ª∞ B√ÅO
# ===============================
target_column = 'cd'
target_name   = 'cd'
fourier = 5
use_log_transform = False

# ===============================
# B∆Ø·ªöC 1: CHU·∫®N B·ªä D·ªÆ LI·ªÜU
# ===============================
file_path = r"D:\quan_ly_tai_nguyen_bien\dataset\data_outliers_as_nan\01_SEDIMENT_SAMPLES\Mirs Bay\MS8.csv"
df = pd.read_csv(file_path)
df['thoi_gian'] = pd.to_datetime(df['thoi_gian'])

df_prophet = (
    df[['thoi_gian', target_column]]
    .rename(columns={'thoi_gian': 'ds', target_column: 'y'})
    .dropna()
    .sort_values('ds')
    .reset_index(drop=True)
)

# L∆∞u d·ªØ li·ªáu g·ªëc ƒë·ªÉ ƒë√°nh gi√° sau
y_original = df_prophet['y'].copy()

# Log transform (n·∫øu b·∫≠t)
if use_log_transform:
    df_prophet['y'] = np.log1p(df_prophet['y'])
    print(f"‚úî ƒê√£ √°p d·ª•ng log(1 + y) cho {target_column}")

# ===============================
# B∆Ø·ªöC 2: CV PARAMETERS
# ===============================
def calculate_cv_params(df, initial_pct=0.7, period_pct=0.05, horizon_pct=0.1):
    total_days = (df['ds'].max() - df['ds'].min()).days
    total_months = total_days / 30.44

    initial = int(max(1, total_months * initial_pct) * 30.44)
    period  = int(max(1, total_months * period_pct) * 30.44)
    horizon = int(max(1, total_months * horizon_pct) * 30.44)

    return f"{initial} days", f"{period} days", f"{horizon} days"

initial_cv, period_cv, horizon_cv = calculate_cv_params(df_prophet)
print(f"üîß CV Params: initial={initial_cv}, period={period_cv}, horizon={horizon_cv}")

# ===============================
# C·∫§U H√åNH C·ªê ƒê·ªäNH
# ===============================
fixed_params = {
    'yearly_seasonality': False,
    'weekly_seasonality': False,
    'daily_seasonality': False,
    'interval_width': 0.8
}

param_grid = {
    'growth': ['linear'],
    'n_changepoints': [5, 10, 15, 25],
    'changepoint_range': [0.8, 0.9],
    'seasonality_mode': ['additive'],
    'seasonality_prior_scale': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],
    'changepoint_prior_scale': [0.01, 0.05, 0.1]
}

# T·∫°o grid
grid = list(itertools.product(
    param_grid['growth'],
    param_grid['n_changepoints'],
    param_grid['changepoint_range'],
    param_grid['seasonality_mode'],
    param_grid['seasonality_prior_scale'],
    param_grid['changepoint_prior_scale']
))

best_mae = float('inf')
best_params = None
best_metrics = None
results = []

print(f"\nüöÄ T·ªïng s·ªë t·ªï h·ª£p c·∫ßn th·ª≠: {len(grid):,} (kho·∫£ng {len(grid)*0.3:.0f}-{len(grid)*0.8:.0f}s)")
print("B·∫Øt ƒë·∫ßu grid search v·ªõi tracking realtime...\n")

# ===============================
# GRID SEARCH (gi·ªØ linear growth - kh√¥ng floor)
# ===============================
for idx, params in enumerate(grid, 1):
    g, n_cp, cp_range, s_mode, s_prior, cp_prior = params
    
    progress = f"[{idx:3d}/{len(grid)} | {idx/len(grid)*100:5.1f}%] "
    
    try:
        model = Prophet(
            **fixed_params,
            growth=g,
            n_changepoints=n_cp,
            changepoint_range=cp_range,
            seasonality_mode=s_mode,
            seasonality_prior_scale=s_prior,
            changepoint_prior_scale=cp_prior
        )
        
        model.add_seasonality(name='yearly', period=365.25, fourier_order=fourier)
        model.fit(df_prophet)

        df_cv = cross_validation(
            model,
            initial=initial_cv,
            period=period_cv,
            horizon=horizon_cv,
            parallel="threads"
        )

        df_p = performance_metrics(df_cv)
        mape = df_p['mape'].mean()
        mae  = df_p['mae'].mean()
        rmse = df_p['rmse'].mean()
        
        metrics = {'mape': mape, 'mae': mae, 'rmse': rmse}
        results.append({'params': params, **metrics})

        if mae < best_mae:
            best_mae = mae
            best_params = params
            best_metrics = metrics
            print(f"{progress}üéØ NEW BEST | "
                  f"n_cp={n_cp}, cp_range={cp_range:.2f}, mode={s_mode}, "
                  f"s_prior={s_prior}, cp_prior={cp_prior} ‚Üí "
                  f"MAPE={mape:.3f}% MAE={mae:.3f} RMSE={rmse:.3f} üíé")
        else:
            print(f"{progress}n_cp={n_cp}, cp_range={cp_range:.2f}, mode={s_mode}, "
                  f"s_prior={s_prior}, cp_prior={cp_prior} ‚Üí "
                  f"MAPE={mape:.3f}% MAE={mae:.3f} RMSE={rmse:.3f} (best MAE: {best_mae:.3f})")

    except Exception as e:
        print(f"{progress}‚ùå L·ªñI: {str(e)[:80]}...")

# ===============================
# IN K·∫æT QU·∫¢ BEST MODEL T·ª™ GRID SEARCH
# ===============================
print("\n" + "="*80)
print("üèÜ B·ªò THAM S·ªê T·ªêT NH·∫§T (CV tr√™n LOG-SPACE)")
print("="*80)

g, n_cp, cp_range, s_mode, s_prior, cp_prior = best_params
print(f"1. n_cp={n_cp}, cp_range={cp_range:.2f}, mode={s_mode}, "
      f"s_prior={s_prior}, cp_prior={cp_prior} ‚Üí "
      f"MAPE={best_metrics['mape']:.3f}% MAE={best_metrics['mae']:.3f} RMSE={best_metrics['rmse']:.3f} üéØ")

print("\n" + "="*80)
print("‚≠ê BEST MODEL CHI TI·∫æT")
print("="*80)
print(f"Growth (grid): {g}")
print(f"n_changepoints: {n_cp}")
print(f"changepoint_range: {cp_range}")
print(f"seasonality_mode: {s_mode}")
print(f"seasonality_prior_scale: {s_prior}")
print(f"changepoint_prior_scale: {cp_prior}")
print(f"CV MAPE: {best_metrics['mape']:.4f}%")
print(f"CV MAE: {best_mae:.4f}")
print(f"CV RMSE: {best_metrics['rmse']:.4f}")

# ===============================
# TRAIN FINAL MODEL V·ªöI LOGISTIC GROWTH + CAP & FLOOR
# ===============================
print("\nüîÑ Training final model v·ªõi logistic growth + cap (q0.98 * 1.2) & floor=0...")

# T√≠nh cap d·ª±a tr√™n quantile 0.98 * 1.2
q98 = y_original.quantile(0.98)
cap_value = q98 * 1.2
floor_value = 0.0

print(f"üîπ Quantile 0.98: {q98:.3f} mg/L ‚Üí Cap = {cap_value:.3f} mg/L (q98 * 1.2)")

# Thi·∫øt l·∫≠p cho d·ªØ li·ªáu hu·∫•n luy·ªán
df_prophet['cap'] = cap_value
df_prophet['floor'] = floor_value

# T·∫°o model logistic
best_model = Prophet(
    **fixed_params,
    growth='logistic',
    n_changepoints=n_cp,
    changepoint_range=cp_range,
    seasonality_mode=s_mode,
    seasonality_prior_scale=s_prior,
    changepoint_prior_scale=cp_prior
)

best_model.add_seasonality(name='yearly', period=365.25, fourier_order=fourier)
best_model.fit(df_prophet)

# T·∫°o future v√† th√™m cap/floor gi·ªëng h·ªát
future = best_model.make_future_dataframe(periods=12, freq='M')
future['cap'] = cap_value
future['floor'] = floor_value

forecast = best_model.predict(future)

# ===============================
# KI·ªÇM TRA V√Ä ƒê√ÅNH GI√Å
# ===============================
print("\nüìà Chi ti·∫øt d·ª± b√°o 12 th√°ng t∆∞∆°ng lai:")
print(forecast.tail(12)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']])

forecast['interval_width'] = forecast['yhat_upper'] - forecast['yhat_lower']
print("\nBi√™n ƒë·ªô kho·∫£ng tin c·∫≠y ·ªü future:")
print(forecast.tail(12)['interval_width'])

if use_log_transform:
    forecast[['yhat', 'yhat_lower', 'yhat_upper']] = np.expm1(
        forecast[['yhat', 'yhat_lower', 'yhat_upper']]
    )

forecast_hist = forecast.iloc[:len(y_original)]
mae_final = mean_absolute_error(y_original, forecast_hist['yhat'])
rmse_final = np.sqrt(mean_squared_error(y_original, forecast_hist['yhat']))
mape_final = np.mean(np.abs((y_original - forecast_hist['yhat']) / y_original)) * 100

print("\n" + "="*80)
print("‚úÖ ƒê√ÅNH GI√Å CU·ªêI C√ôNG (SCALE G·ªêC ‚Äì mg/L) - FINAL FIT")
print("="*80)
print(f"MAE  : {mae_final:.3f} mg/L")
print(f"RMSE : {rmse_final:.3f} mg/L")
print(f"MAPE : {mape_final:.2f} %")

# ===============================
# TR·ª∞C QUAN H√ìA
# ===============================
plt.figure(figsize=(15,8))
plt.plot(df_prophet['ds'], y_original, 'o-', markersize=4, label='Th·ª±c t·∫ø (As - mg/L)', alpha=0.7)
plt.plot(forecast['ds'], forecast['yhat'], 'r-', linewidth=2.5, label='D·ª± b√°o (Logistic + Floor=0)')
plt.fill_between(
    forecast['ds'],
    forecast['yhat_lower'],
    forecast['yhat_upper'],
    alpha=0.25,
    color='red',
    label='Kho·∫£ng tin c·∫≠y 80%'
)
plt.axvline(df_prophet['ds'].max(), color='gray', linestyle='--', linewidth=2, label='B·∫Øt ƒë·∫ßu d·ª± b√°o')
plt.xlabel("Th·ªùi gian", fontsize=12)
plt.ylabel(f"{target_name} (mg/L)", fontsize=12)
plt.title(f"üöÄ D·ª± b√°o {target_name.upper()} - Deep Bay DS1 (Logistic Growth + Floor=0)\n"
          f"Best: MAPE={mape_final:.1f}% | RMSE={rmse_final:.2f} mg/L", fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("\nüìä Components plot:")
best_model.plot_components(forecast)
plt.suptitle(f"Ph√¢n t√≠ch th√†nh ph·∫ßn - {target_name.upper()} (Best Model - Logistic + Floor=0)", fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

total_time = time.time() - start
print(f"\n‚è±Ô∏è T·ªïng th·ªùi gian ch·∫°y: {total_time:.1f}s ({total_time/len(grid):.1f}s/t·ªï_h·ª£p)")
print(f"‚úÖ Ho√†n th√†nh! D·ª± b√°o gi·ªù kh√¥ng c√≥ gi√° tr·ªã √¢m v√† ·ªïn ƒë·ªãnh h∆°n nh·ªù logistic growth + floor=0.")

# L∆∞u k·∫øt qu·∫£ grid search
results_df = pd.DataFrame(results)
results_df.to_csv(f'prophet_gridsearch_results_{target_column}.csv', index=False)
print(f"üíæ ƒê√£ l∆∞u {len(results)} k·∫øt qu·∫£ grid search ‚Üí prophet_gridsearch_results_{target_column}.csv")

# ===============================
# L∆ØU MODEL ƒê·ªÇ S·ª¨ D·ª§NG SAU (TH√äM PH·∫¶N N√ÄY V√ÄO CU·ªêI SCRIPT)
# ===============================
from prophet.serialize import model_to_json
import joblib
import json
import os

# T·∫°o th∆∞ m·ª•c l∆∞u n·∫øu ch∆∞a c√≥ (t√πy ch·ªçn)
save_dir = "prophet_saved_models"
os.makedirs(save_dir, exist_ok=True)

# T√™n file chung
model_name = f"prophet_model_{target_column}_deepbay_ds1"

# 1. L∆∞u model b·∫±ng JSON (ph∆∞∆°ng th·ª©c ch√≠nh th·ª©c c·ªßa Prophet)
json_path = os.path.join(save_dir, f"{model_name}.json")
with open(json_path, 'w', encoding='utf-8') as fout:
    fout.write(model_to_json(best_model))
print(f"‚úÖ ƒê√£ l∆∞u model (JSON): {json_path}")

# 2. L∆∞u model b·∫±ng joblib/pickle (nhanh, ti·ªán d√πng sau n√†y)
pkl_path = os.path.join(save_dir, f"{model_name}.pkl")
joblib.dump(best_model, pkl_path)
print(f"‚úÖ ƒê√£ l∆∞u model (Pickle): {pkl_path}")

# 3. L∆∞u c·∫•u h√¨nh quan tr·ªçng (cap, floor, th√¥ng tin d·ªØ li·ªáu)
config = {
    'target_column': target_column,
    'target_name': target_name,
    'site': 'Deep Bay DS1',
    'train_start_date': str(df_prophet['ds'].min().date()),
    'train_end_date': str(df_prophet['ds'].max().date()),
    'total_observations': len(df_prophet),
    'cap_value': float(cap_value),
    'floor_value': float(floor_value),
    'q98_original': float(q98),
    'fourier_order': fourier,
    'use_log_transform': use_log_transform,
    'final_mae': float(mae_final),
    'final_rmse': float(rmse_final),
    'final_mape': float(mape_final),
    'best_params': {
        'n_changepoints': n_cp,
        'changepoint_range': cp_range,
        'seasonality_mode': s_mode,
        'seasonality_prior_scale': s_prior,
        'changepoint_prior_scale': cp_prior
    }
}

config_path = os.path.join(save_dir, f"{model_name}_config.json")
with open(config_path, 'w', encoding='utf-8') as f:
    json.dump(config, f, indent=4, default=str)

print(f"‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh model: {config_path}")

print("\n" + "="*80)
print("üéâ HO√ÄN T·∫§T L∆ØU MODEL!")
print("="*80)
print(f"T·∫•t c·∫£ file ƒë√£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c: ./{save_dir}/")
print("   ‚Ä¢ Model JSON:      d·ªÖ ƒë·ªçc, ch√≠nh th·ª©c")
print("   ‚Ä¢ Model Pickle:    nhanh khi load")
print("   ‚Ä¢ Config JSON:     ch·ª©a cap, floor, th√¥ng tin train")
print("\nSau n√†y b·∫°n ch·ªâ c·∫ßn load model + config ‚Üí predict ngay l·∫≠p t·ª©c!")
print("V√≠ d·ª• load & predict s·∫Ω ƒë∆∞·ª£c cung c·∫•p ri√™ng n·∫øu c·∫ßn.")
print("="*80)